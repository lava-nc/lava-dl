{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534eb501-a3d6-4871-b989-ecfd3963b9d4",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "\n",
    "This tutorial demonstrates how to use the `lava.lib.dl.netx` API to classify MNIST images using an already trained `lava.lib.dl.slayer` network; i.e., we do _no_ training here, just inference. The classification is done on both: CPU (via $\\texttt{Loihi2SimCfg}$) and on Loihi-2 neuro-cores (via $\\texttt{Loihi2HwCfg}$). \n",
    "\n",
    "Note that this inference tutorial is part of the **end-to-end training** and **evaluation** tutorial: [mnist-on-loihi](https://github.com/R-Gaurav/mnist-on-loihi) -- it contains all the inference code explained here, as well as the `slayer` training code to obtain the trained network-weights (used here). The `slayer` training procedure is also explained in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html) and is quite straight-forward. However, when it comes to inference, there are some tips-and-tricks to keep in mind while evaluating the trained `slayer`-network via `netx`; and that's precisely the point of this tutorial. \n",
    "\n",
    "## `slayer` Network Architecture\n",
    "The architecture of the trained `slayer`-network is as follows: \n",
    "$$\\texttt{Dense CUBA(128)} \\rightarrow \\texttt{Dense CUBA(64)} \\rightarrow \\texttt{Dense CUBA(10)}$$\n",
    "where, `Dense` denotes the fully connected `Dense` connection, and `CUBA(m)` denotes $\\texttt{m}$ Current Based neurons. Note that the first **Hidden** layer: $\\texttt{Dense CUBA(128)}$ accepts $784$-dimensional rate-encoded spikes (of the flattened MNIST images), and the (last) **Output** layer: $\\texttt{Dense CUBA(10)}$ consists of $10$ output neurons denoting the classes; classification is done on the maximally spiking output neuron.\n",
    "\n",
    "## Loihi-2 deployment\n",
    "To deploy and evaluate the above (trained) `slayer`-network on Loihi-2 boards, we are going to load it via `netx` and connect **Input** and **Output** `Process`es (to its ends), which will encode the test-image to input spikes and predict the class from the output spikes, respectively. Note that since the `slayer`-network is loaded via `netx`, we also call it as <ins>`netx`-obtained network</ins> here (and use the terms interchangeably as appropriate); the architecture for Loihi-2 deployment is _conceptually_ going to look like: **Input** `Process` -> `netx`-obtained network -> **Output** `Process`.\n",
    "\n",
    "Without further ado, let's start by importing the necessary libraries/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a63aef-92a4-48c5-88cb-91a004279f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from lava.lib.dl import netx\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg, Loihi2HwCfg\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "\n",
    "from utils import (InputAdapter, PyInputAdapter, NxInputAdapter,\n",
    "                   OutputAdapter, PyOutputAdapter, NxOutputAdapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044fd7f-4e92-4cef-908f-676c78ff2afe",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to encode Images to **Input** Spikes\n",
    "As mentioned earlier, the first **Hidden** layer (in the `netx`-obtained network) accepts a $784$-dimensional spike vector corresponding to a flattened MNIST image. Therefore, we need to write down the **Input** `Process` which will rate-encode the pixels to binary spikes; note that while training the above `slayer`-network, the pixels were first normalized between $[0, 1]$ and then rate-encoded via the following equation:\n",
    "$$J = \\alpha<e.x> + \\beta$$\n",
    "where $J$ is the input current to encoding neuron, $e$ is the encoder, $x$ is the normalized pixel value, and $\\alpha$ and $\\beta$ are the neuron's `gain` and `bias` values; their values are $e=1$ (since $x>=0$ always), $\\alpha=1$ and $\\beta=0$. We will use the same above equation (for $J$) to rate-encode the normalized pixels to spikes in our **Input** `Process`: $\\texttt{InpImgToSpk}$ below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccdbc45-478e-4ece-b513-47d9162fd65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InpImgToSpk(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Input process to convert flattened images to binary spikes.\n",
    "  \"\"\"\n",
    "  def __init__(self, img_shape, n_tsteps, curr_img_id, v_thr=1):\n",
    "    super().__init__()\n",
    "    self.spk_out = OutPort(shape=(img_shape, ))\n",
    "    self.label_out = OutPort(shape=(1, ))\n",
    "\n",
    "    self.curr_img_id = Var(shape=(1, ), init=curr_img_id)\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps)\n",
    "    self.inp_img = Var(shape=(img_shape, ))\n",
    "    self.ground_truth_label = Var(shape=(1, ))\n",
    "    self.v = Var(shape=(img_shape, ), init=0)\n",
    "    self.vth = Var(shape=(1, ), init=v_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9985a5c-2153-442d-a6c3-0af5ac302fa1",
   "metadata": {},
   "source": [
    "Now that we have defined the `Process`: $\\texttt{InpImgToSpk}$, let's implement its corresponding `ProcessModel`: $\\texttt{PyInpImgToSpkModel}$ that will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e5261b-519f-4523-880a-42bf21dcfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=InpImgToSpk, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyInpImgToSpkModel(PyLoihiProcessModel):\n",
    "  \"\"\"\n",
    "  Python implementation for the above `InpImgToSpk` process.\n",
    "  \"\"\"\n",
    "  spk_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "  label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32, precision=32)\n",
    "\n",
    "  curr_img_id: int = LavaPyType(int, int, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  inp_img: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "  v: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  vth: float = LavaPyType(float, float)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.mnist_dset = MnistDataset()\n",
    "    self.gain = 1\n",
    "    self.bias = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for post-management phase, necessary to update the next image\n",
    "    index after the current image is processed.\n",
    "\n",
    "    Note: The execution control calls `post_guard()` after `run_spk()` every\n",
    "    time-step, before updating the `self.time_step` variable to next time-step.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1: # n_ts steps passed, one image processed.\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-management phase executed only when the above `post_guard()` returns\n",
    "    True -> then, move to the next image, reset the neuron states, etc.\n",
    "    \"\"\"\n",
    "    img = self.mnist_dset.test_images[self.curr_img_id]\n",
    "    self.inp_img = img/255\n",
    "    self.ground_truth_label = self.mnist_dset.test_labels[self.curr_img_id]\n",
    "    self.label_out.send(np.array([self.ground_truth_label]))\n",
    "    self.v = np.zeros(self.v.shape, dtype=float)\n",
    "    self.curr_img_id += 1\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase, this is executed every simulation time-step unconditionally,\n",
    "    and first in order of all the phases.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1:\n",
    "     self.inp_img = np.zeros(self.inp_img.shape, dtype=float)\n",
    "     self.v = np.zeros(self.v.shape, dtype=float)\n",
    "\n",
    "    J = self.gain*self.inp_img + self.bias\n",
    "    self.v[:] = self.v[:] + J[:]\n",
    "    mask = self.v > self.vth\n",
    "    self.v[mask] = 0\n",
    "    self.spk_out.send(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce0eae-0440-4a51-b732-e700d2acb1a8",
   "metadata": {},
   "source": [
    "There are a bunch of important points to note here:\n",
    "* Lava's execution/run `time-step` starts from $1$, and\n",
    "* Whenever the run time-step is one more than a multiple of the image presentation - $\\texttt{self.n_ts}$ time-steps (per-image):\n",
    "    * The $\\texttt{run_spk()}$ phase resets the input image variable: $\\texttt{self.inp_img}$ and the encoding neuron's voltage: $\\texttt{self.v}$ to all zeros, and\n",
    "    * The $\\texttt{post_guard()}$ phase returns $\\texttt{True}$ and the $\\texttt{run_post_mgmt()}$ phase gets called, which also resets the necessary variables\n",
    "\n",
    "Let's look into these phases' operations more closely; note that they are discussed in considerable details (on a per time-step basis) in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html). \n",
    "\n",
    "As you would know, in each time-step, the $\\texttt{run_spk()}$ phase is the first phase to be executed among $\\texttt{post_guard()}$ and $\\texttt{run_post_mgmt()}$ phases. Therefore, when the $\\texttt{InpImgToSpk}$ `Process`'s execution starts, i.e., time-step $=1$, the $\\texttt{self.inp_img}$ and $\\texttt{self.v}$ are both reset to all zeros in $\\texttt{run_spk()}$, and since $\\texttt{post_guard()}$ returns $\\texttt{True}$, the $\\texttt{run_post_mgmt()}$ phase updates $\\texttt{self.inp_img}$ to the first test-image (assuming $\\texttt{self.curr_img_id}$ is set to start from $0$), as well as the other related variables. In the subsequent time-steps $\\texttt{run_spk()}$ keeps getting called and the rate-encoding of $\\texttt{self.inp_img}$ progresses.\n",
    "\n",
    "When the per-image presentation time-steps (i.e., $\\texttt{self.n_ts}$) are over, i.e., in the $(\\texttt{self.n_ts} + 1)^{\\text{th}}$ time-step, $\\texttt{run_spk()}$ is called gain, but note that $\\texttt{self.inp_img}$ is still the previous _old_ image, therefore, it's important to reset the $\\texttt{self.inp_img}$ and $\\texttt{self.v}$ in $\\texttt{run_spk()}$ to ensure that the previous old image does _not_ corrupt the prediction corresponding to the new (to be updated) image. In the same $(\\texttt{self.n_ts} + 1)^{\\text{th}}$ time-step, $\\texttt{post_guard()}$ returns $\\texttt{True}$ and the $\\texttt{run_post_mgmt()}$ phase finally updates $\\texttt{self.inp_img}$ to the next new image (along with updating the ground truth).\n",
    "\n",
    "Thus, it is important to reset $\\texttt{self.inp_img}$ and $\\texttt{self.v}$ in the $\\texttt{run_spk()}$ phase in every $(k\\times\\texttt{self.n_ts} + 1)^{\\text{th}}$ time-step, where $k \\in \\mathbb{W}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6b850-71c4-4c1a-8cb8-9b353a09c0bc",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to infer Classes from **Output** Spikes\n",
    "As mentioned before, the **Output** layer -- composed of $10$ neurons (each denoting a class) in the `netx`-obtained network produces spikes, upon which we can infer classes by accumulating them over a period of $\\texttt{self.n_ts}$ time-steps (for each image) and reporting the index which has the maximum number of accumulated spikes. To do the same, we write down the following **Output** `Process`: $\\texttt{OutSpkToCls}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818d6fbb-9c0e-4802-843b-c589339743b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutSpkToCls(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Output process to collect output neuron spikes and infer predicted class.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_tsteps, num_test_imgs, n_cls_shape=(10, )):\n",
    "    super().__init__()\n",
    "    self.spikes_in = InPort(shape=n_cls_shape) # Receives output spikes.\n",
    "    self.label_in = InPort(shape=(1, )) # Receives ground truth labels.\n",
    "    self.spikes_accum = Var(shape=n_cls_shape) # Accum. spikes for prediction.\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps) # Image presentation time.\n",
    "    self.pred_labels = Var(shape=(num_test_imgs, ))\n",
    "    self.true_labels = Var(shape=(num_test_imgs, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a4c2e-a974-4438-8060-683869ed0035",
   "metadata": {},
   "source": [
    "Now that we have the $\\texttt{OutSpkToCls}$ `Process` ready, let's write down its corresponding `ProcessModel`: $\\texttt{PyOutSpkToClsModel}$ that runs on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1054667c-ecbf-466a-b420-9ee491d844ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=OutSpkToCls, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutSpkToClsModel(PyLoihiProcessModel):\n",
    "  spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "  label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "  spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "  true_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.curr_idx = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for Post-Management phase.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 0:\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-Management phase: executed only when the guard function above returns\n",
    "    True.\n",
    "    \"\"\"\n",
    "    true_label = self.label_in.recv()\n",
    "    pred_label = np.argmax(self.spikes_accum)\n",
    "    self.true_labels[self.curr_idx] = true_label[0]\n",
    "    self.pred_labels[self.curr_idx] = pred_label\n",
    "    self.curr_idx += 1\n",
    "    self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase: executed unconditionally at every time-step, first in order\n",
    "    among all the phases.\n",
    "    \"\"\"\n",
    "    spk_in = self.spikes_in.recv()\n",
    "    self.spikes_accum = self.spikes_accum + spk_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f0587-1d74-49c8-807f-00ac4bfd0326",
   "metadata": {},
   "source": [
    "As can be seen above, the $\\texttt{post_guard()}$ phase returns $\\texttt{True}$ in every $(k\\times\\texttt{self.n\\_ts})^{\\text{th}}$ time-step, where $k\\in\\mathbb{W}$, and thus, the $\\texttt{run\\_post\\_mgmt()$ phase gets evaluated in the very same time-step. Let's look into the operation of these phases more closely; per time-step operation details can be found in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html).\n",
    "\n",
    "As you already know, the Lava run time-step starts with $1$ and $\\texttt{run\\_spk()}$ is the first phase to be called every time-step in a `Process`'s execution. Here, in the $1^{\\text{st}}$ time-step, the $\\texttt{run\\_spk()}$ phase is called first and it accumulates the incoming spikes from the **Output** layer of the `netx`-obtained network; $\\texttt{post\\_guard()}$ returns $\\texttt{False}$ and $\\texttt{run\\_post\\_mgmt()}$ is _not_ called. Such processing continues until the $\\texttt{self.n\\_ts}^{\\text{th}}$ time-step arrives. In the time-step $=\\texttt{self.n\\_ts}$, $\\texttt{run\\_spk()}$ still accumulates the output spikes corresponding to the first input image, post which, $\\texttt{post\\_guard()}$ returns $\\texttt{True}$ and $\\texttt{run\\_post\\_mgmt()}$ subsequently computes the index of the maximally spiking neuron as the predicted class (other variables are accordingly reset or updated). \n",
    "\n",
    "For the next time-steps, i.e., $(\\texttt{self.n\\_ts} + 1)^{\\text{th}}$ onwards, the execution of $\\texttt{OutSpkToCls}$ `Process` continues as explained above, but with the updated $\\texttt{self.inp\\_img}$ in the $\\texttt{InpImgToSpk}$ `Process`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5d3be-7713-4493-b1a5-396da3bdb78a",
   "metadata": {},
   "source": [
    "# Load the `slayer`-trained weights\n",
    "\n",
    "Now that both the **Input** and **Output** `Process`es are ready, we can proceed with loading the (trained) `slayer`-network via `netx`. However, before we do that, note that the `slayer`-network was trained for $20$ time-steps each, on MNIST training images. Therefore, the test-image presentation time-steps, i.e., $\\texttt{self.n_ts}$ should be $20$ time-steps during inference as well. In the code below, $\\texttt{n_tsteps}$ denotes the test-image presentation time-steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46eaf699-548e-41ec-88d8-b156ddc7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `n_tsteps` is the presentation time-steps of each test-image.\n",
    "#n_tsteps = 20  \n",
    "n_tsteps = 32 # Since reset_interval on Loihi-2 Hardware has to be a power of 2.\n",
    "\n",
    "# `num_test_images` is the number of test-images to do inference on.\n",
    "num_test_imgs = 25\n",
    "\n",
    "net = netx.hdf5.Network(\n",
    "    net_config=\"./trained_mnist_network.net\", # Trained network path.\n",
    "    reset_interval=n_tsteps, # Presentation time-steps of each test-image.\n",
    "    reset_offset=1 # Phase shift / offset time-step to reset this network.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b09d7-78e4-4e9d-88a8-87d8d8883e0e",
   "metadata": {},
   "source": [
    "Note the two important nuances above:\n",
    "* $\\texttt{reset\\_interval}$ is set equal to $\\texttt{n\\_tsteps}$, which implies that the `netx`-obtained network is reset after every $\\texttt{n\\_tsteps}$ time-steps, however\n",
    "* $\\texttt{reset\\_offset}$ is set equal to $1$, which implies that the network is reset with a phase shift of $1$ time-step (an important detail here)\n",
    "\n",
    "In other words, $\\texttt{reset_offset}=1$ implies that the count of $\\texttt{reset_interval}=\\texttt{n_tsteps}$ starts after the time-step $1$ is over. That is, in the above cell's code, if $\\texttt{n_tsteps}=20$, then the `netx`-obtained network: $\\texttt{net}$ is reset after $21^{\\text{st}}, 41^{\\text{st}}, 61^{\\text{st}}, \\cdots$ time-steps. The next step is to instantiate the `Process`es and connect them appropriately, followed by their execution on either $\\textsf{Loihi-2 Simulation}$ or $\\textsf{Loihi-2 Hardware}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f0b6-8982-4913-a410-8d5da47aaa18",
   "metadata": {},
   "source": [
    "# Instantiating and Connecting `Process`es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07debd87-f890-4ffb-ae82-e0920227a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Processes.\n",
    "\n",
    "# `curr_img_id=0` implies that inference starts from test image at index 0.\n",
    "img_to_spk = InpImgToSpk(img_shape=784, n_tsteps=n_tsteps, curr_img_id=0)\n",
    "\n",
    "spk_to_cls = OutSpkToCls(n_tsteps=n_tsteps, num_test_imgs=num_test_imgs)\n",
    "inp_adp = InputAdapter(shape=net.inp.shape)\n",
    "out_adp = OutputAdapter(shape=net.out.shape)\n",
    "\n",
    "# Connect Processes.\n",
    "img_to_spk.spk_out.connect(inp_adp.inp)\n",
    "inp_adp.out.connect(net.inp)\n",
    "net.out.connect(out_adp.inp)\n",
    "out_adp.out.connect(spk_to_cls.spikes_in)\n",
    "# Connect ImgToSpk Input directly to SpkToCls Output for ground truths.\n",
    "img_to_spk.label_out.connect(spk_to_cls.label_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24bb38-40ec-4c62-b674-e7527b511db1",
   "metadata": {},
   "source": [
    "Building all the fundamental components to deploy our `slayer`-network on Loihi is done now; except that we still need adapters to transfer spikes to-and-fro between the CPU and the Loihi neuro-cores. Those adapters are straightforward to understand and are already written in the $\\texttt{utils.py}$ file in this current directory. We next simply call the function $\\texttt{get_run_config()}$ with appropriate $\\texttt{backend}$ argument to deploy our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c01e03a-305f-48be-9d89-35a5d5b5b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_config(backend):\n",
    "  \"\"\"\n",
    "  Returns the run-time config corresponding to the `backend`.\n",
    "\n",
    "  Args:\n",
    "    backend <str>: Either \"L2Sim\" or \"L2Hw\" for Loihi2SimCfg or Loihi2HwCfg.\n",
    "  \"\"\"\n",
    "  assert backend in [\"L2Sim\", \"L2Hw\"]\n",
    "\n",
    "  if backend == \"L2Sim\": # Run on the Loihi-2 Simulation Hardware on CPU.\n",
    "    run_config = Loihi2SimCfg(\n",
    "        select_tag=\"fixed_pt\", # To select fixed point implementation.\n",
    "        exception_proc_model_map={\n",
    "            InpImgToSpk: PyInpImgToSpkModel,\n",
    "            OutSpkToCls: PyOutSpkToClsModel,\n",
    "            InputAdapter: PyInputAdapter,\n",
    "            OutputAdapter: PyOutputAdapter\n",
    "            }\n",
    "        )\n",
    "  elif backend == \"L2Hw\": # Run on the Loihi-2 Physical Hardware on INRC.\n",
    "    run_config = Loihi2HwCfg(\n",
    "        select_sub_proc_model=True,\n",
    "        exception_proc_model_map={\n",
    "            InpImgToSpk: PyInpImgToSpkModel,\n",
    "            OutSpkToCls: PyOutSpkToClsModel,\n",
    "            InputAdapter: NxInputAdapter,\n",
    "            OutputAdapter: NxOutputAdapter\n",
    "            }\n",
    "        )\n",
    "  return run_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73dfa4-bddc-4d29-bd44-a6a919f08313",
   "metadata": {},
   "source": [
    "# Inference on CPU and Loihi-2 Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc91795f-dc10-410b-b14e-be195d2c7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(backend, is_log=False):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    backend <str>: \"L2Sim\" for deployment on CPU, \"L2Hw\" for deployment on \n",
    "                   Loihi-2 Hardware.\n",
    "    is_log <bool>: Log the execution steps on Loihi-2 Hardware if True.\n",
    "  \"\"\"\n",
    "  assert backend in [\"L2Sim\", \"L2Hw\"]\n",
    "  run_config = get_run_config(backend=backend)\n",
    "  if is_log and backend==\"L2Hw\":\n",
    "    img_to_spk._log_config.level = logging.INFO\n",
    "  \n",
    "  for _ in range(num_test_imgs):\n",
    "    img_to_spk.run(\n",
    "      condition=RunSteps(num_steps=n_tsteps), run_cfg=run_config\n",
    "    )\n",
    "  ground_truths = spk_to_cls.true_labels.get().astype(np.int32)\n",
    "  predtd_clsses = spk_to_cls.pred_labels.get().astype(np.int32)\n",
    "\n",
    "  img_to_spk.stop()\n",
    "  print(\"Accuracy on Loihi {0}: \".format(\n",
    "        \"Simulation\" if backend==\"L2Sim\" else \"Board\"),\n",
    "        np.mean(np.array(ground_truths) == np.array(predtd_clsses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bd53fc-b1af-4243-a925-8e87689ed626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning converged after iteration=5\n",
      "Per core utilization:\n",
      "-------------------------------------------------------------------------\n",
      "| AxonIn |NeuronGr| Neurons|Synapses| AxonMap| AxonMem|  Total |  Cores |\n",
      "|-----------------------------------------------------------------------|\n",
      "|   0.40%|  12.50%|   0.24%|   1.60%|   0.06%|   0.00%|   1.71%|       1|\n",
      "|   0.80%|  12.50%|   1.56%|  16.80%|   0.40%|   0.00%|  14.72%|       1|\n",
      "|   4.90%|  12.50%|   1.22%|  78.40%|   0.31%|   0.00%|  67.14%|       3|\n",
      "|-----------------------------------------------------------------------|\n",
      "| Total                                                        |       5|\n",
      "-------------------------------------------------------------------------\n",
      "Accuracy on Loihi Board:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Execute.\n",
    "run_inference(\"L2Hw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
